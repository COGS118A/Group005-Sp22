{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Hsi Chen\n",
    "- Brandon Vazquez-Tellez\n",
    "- Vicky Chou\n",
    "- Adam Yoshinaga\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    " Our goal is to train a regression model with a large dataset of review descriptions and various app data from the Google Play Store to predict ratings for apps. This is important beacuse it will allow us to predict how an app will likely perform, which has numerous applications, such as identifying trends, predicting user behavior, and marketing performance. We plan to do this initially by the use of a simple OLS/Linear Regression model, but then increasing the complexity by implementing gradient boosted decision trees through XGBoost, and then comparing them and using cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "As our daily routines depend more on mobile apps, apps with high ratings can suggest different meanings like how entertaining apps are or how helpful they are in our lives. Certain apps may become more popular as users give higher ratings, and people are more willing to download and use apps with higher ratings. Different models have been used to predict app ratings, such as Random Forest Regressor or XGboost models used to predict Google Apps Rating in this dataset[1]. Such predictions take into account of areas like app category, price, content rating, number of installs, or reviews to see what features influence the ratings more. An area of ongoing research in machine learning is natural language processing, which is a field that uses algorithms for detecting words in sentences and interpreting the semantics behind the way the words were phrased. Natural language processing could potentially be used to analyze app ratings when considering users' reviews, but not much has actually been done to determine how 'good' or how high of a rating the application deserves based on the pattern between the words used in reviews and the rating given [2]. Linear regression is one of the most popular and most widely used algorithms. Being one of the oldest techniques, we can also say that it is one of those algorithms which have been studied immensely to understand and implement. Hence you will find a million different implementations and names for Linear Regression[3]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "## TODO: Implement suggestions from issues\n",
    "\n",
    "\n",
    "The problem we are solving is predicting an app's rating, which is quantifiable, measurable, and replicable, by analyzing which components of an app predict/impact its rating more accurately as well as to what degree. By figuring out these, we can understand the features that constitute to an app's success and hence eliminate aspects of an app that drag down its ratings. Predictions of app ratings are quantifiable and measurable as they are measured in a mathematical scale. It is replicable because we can calculate the ratings based on differences in an app's features. Some ML-relevant potential solutions are Ordinary Least Squares, one-hot encoding, data wrangling, linear regression, and other Python functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "* Link: https://www.kaggle.com/code/jemseow/machine-learning-to-predict-app-ratings\n",
    "* Size of the dataset: # of variables - 10; # of observations - 9660\n",
    "* An observation consists of the app name and its category, rating, number of reviews, size, number of installs, trial type, price, content rating, and genres.\n",
    "* Some critical variables are rating and reviews since they are directly related to people's opinions and ratings of the app. Ratings are represented through numbers on a scale of 1 to 19, and the number of reviews are represented through numbers ranging from 0 to 78.2m.\n",
    "* One-hot encoding, data wrangling, and implementation of methods we have learned in this class will be needed. \\\n",
    "* **Cleaning methods**: Remove nulls, fill missing values with median, remove special characters from the string and convert it into usable format. \n",
    "\n",
    "**Want to find another dataset with text data for reviews**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "### **TODO: Implement Suggestions from issues**\n",
    "\n",
    "Since we are planning on using a regression model to predict app ratings from different features, one of the evaluation metrics we'll probably be using is the mean square error to determine the goodness of fit. Mean square error is calculated by the sum of the square of prediction error (expected output minus predicted output) divided by the number of data points, suggesting how far off our rating predictions are from the actual expected results. Another potential metric is using the mean absolute error, which is the same as mean square error except it takes the absolute value of prediction error instead of the square, to determine how far off our predictions are if we treat all errors the same. Mean square error will penalize big rating prediction errors more due to the square, but both metrics may be potential ways we could use to identify how good of a fit our model is. \\\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n",
    "\n",
    "NEW SECTION!\n",
    "\n",
    "Please show any preliminary results you have managed to obtain.\n",
    "\n",
    "Examples would include:\n",
    "- Analyzing the suitability of a dataset or alogrithm for prediction/solving your problem \n",
    "- Performing feature selection or hand-designing features from the raw data. Describe the features available/created and/or show the code for selection/creation\n",
    "- Showing the performance of a base model/hyper-parameter setting.  Solve the task with one \"default\" algorithm and characterize the performance level of that base model.\n",
    "- Learning curves or validation curves for a particular model\n",
    "- Tables/graphs showing the performance of different models/hyper-parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important for us to gather accurate data by checking its accuracy and reliability. It is also important for us to make sure that the data can be acquired by the public and is permitted by the owner. We need to be neutral about the evaluations and rely on evidence instead of assumptions. As for people's reviews on the apps, we should keep them anonymous in order to protect their privacies. A tool that can help us address these potential issues is https://deon.drivendata.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Be responsible and complete individual tasks on time.\n",
    "* Show up to group meetings/calls.\n",
    "* Respond to groupchat messages.\n",
    "* Respect each other.\n",
    "* Ask for help when stuck on individual parts.\n",
    "* Help each other when in need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE THE PROPOSAL TIMELINE ACCORDING TO WHAT HAS ACTUALLY HAPPENED AND HOW IT HAS EFFECTED YOUR FUTURE PLANS\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic (Pel√©) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"houdnote\"></a>1.[^](#houd): Houd, Anass El (19 Sept 2020) DS Project: How to Predict Google Apps Rating? *Towards Data Science*. https://towardsdatascience.com/ds-project-how-to-predict-google-apps-rating-618ebc77cad<br> \n",
    "<a name=\"lutkevichnote\"></a>2.[^](#lutkevich): Lutkevich, Ben (Mar 2021) What is Natural Language Processing? An Introduction to NLP *Tech Target*. https://www.techtarget.com/searchenterpriseai/definition/natural-language-processing-NLP#:~:text=Natural%20language%20processing%20(NLP)%20is,in%20the%20field%20of%20linguistics<br>\n",
    "<a name=\"pandeynote\"></a>3.[^](#pandey): Pandey, Pranjal (7 Sept 2021) Machine Learning: Linear Regression and its applications *The Data Science Portal*. https://thedatascienceportal.com/posts/linear-regression-and-its-applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
